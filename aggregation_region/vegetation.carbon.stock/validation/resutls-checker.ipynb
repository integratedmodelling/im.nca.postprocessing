{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"required libraries\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Check if every file year/class has all the countries\"\"\"\n",
    "# path = \"Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global_results\"\n",
    "path = r\"C:\\Users\\admin\\Documents\\01_Ruben_Scripts\\im.nca.postprocessing\\aggregation_region\\vegetation.carbon.stock\\tmp\\vcs.aggregated.country\"\n",
    "os.chdir(path)\n",
    "files = os.listdir(path)\n",
    "\n",
    "error_files = []\n",
    "for file in files: # [0:1]\n",
    "    results_df = pd.read_csv(file)\n",
    "    # There will be total csv and the ones for year / LC.\n",
    "    # Here we filter the total ones\n",
    "    if file.startswith(\"vegetation\"): \n",
    "        if len(results_df) != 265: # It has to take all 265 countries\n",
    "            error_files.append(file)\n",
    "        else:\n",
    "            continue\n",
    "         \n",
    "    #TODO: we can also check countries that contain -9999 values. These ones might need to be recalculated\n",
    "    #sometimes not, since it is expected a 0 value, compare with the other years.\n",
    "print(error_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vegetation-carbon-stock_2001_201.csv', 'vegetation-carbon-stock_2002_90.csv', 'vegetation-carbon-stock_2003_11.csv', 'vegetation-carbon-stock_2004_72.csv', 'vegetation-carbon-stock_2006_30.csv', 'vegetation-carbon-stock_2007_160.csv', 'vegetation-carbon-stock_2008_120.csv', 'vegetation-carbon-stock_2009_12.csv']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"files that have -9999 values\"\"\"\n",
    "error_files= []\n",
    "for file in files[:]: # [0:1]\n",
    "    results_df = pd.read_csv(file)\n",
    "    # There will be total csv and the ones for year / LC.\n",
    "    # Here we filter the total ones\n",
    "    #change the -9999 value to 0\n",
    "\n",
    "    # df.loc[df[\"gender\"] == \"male\", \"gender\"] = 1\n",
    "    counter = 0\n",
    "    for row_index, row in results_df.iterrows():\n",
    "        value = row[1]\n",
    "        index_value = row[0]\n",
    "        if value == -9999.0 and index_value != (171.0 or 226.0): # It has to take all 265 countries\n",
    "            counter += 1\n",
    "            if counter > 4 and file not in error_files: #if there are more than 6 values with -9999 we are really having a problem\n",
    "                error_files.append(file)\n",
    "        else: \n",
    "            continue\n",
    "    #TODO: we can also check countries that contain -9999 values. These ones might need to be recalculated\n",
    "    #sometimes not, since it is expected a 0 value, compare with the other years.\n",
    "print(error_files)\n",
    "print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove all the -9999 values\"\"\"\n",
    "for file in files[:]: # [0:1]\n",
    "    results_df = pd.read_csv(file)\n",
    "    #create a copy of the dataframe\n",
    "    df_copy = results_df.copy()\n",
    "    #delete the unnamed column it creates\n",
    "    df_copy = df_copy.drop([df_copy.columns[0]], axis=1)\n",
    "    #get the column name\n",
    "    column_name = results_df.columns[1]\n",
    "    # change the value\n",
    "    df_copy[column_name] = df_copy[column_name].replace([-9999], 0)\n",
    "    # rewrite the file\n",
    "    df_copy.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Move the files from one folder to another\"\"\"\n",
    "\n",
    "# VM 126 / 127 settings \n",
    "raster_path = r\"Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global\"\n",
    "raster_destination = r\"Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global_finished\"\n",
    "# VM 120 settings\n",
    "# raster_path = r\"/home/ubuntu/vcs_wb/by_landcover/vegetation_carbon_stock_landcover_global/\"\n",
    "# raster_destination = r\"/home/ubuntu/vcs_wb/by_landcover/already_processed_layers\"\n",
    "\n",
    "for file in files: # [0:1]\n",
    "    landcover_class = re.findall(r'\\d+', file)[1]\n",
    "    year = re.findall(r'\\d+', file)[0]\n",
    "    results_df = pd.read_csv(file)\n",
    "    if file.startswith(\"vegetation\"):\n",
    "        #move the file\n",
    "        #move the files from one folder to anotjher\n",
    "        shutil.move(raster_path + \"/vcs_\" + year + \"_global_300m_\" + landcover_class + \".tif \", raster_destination)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "120 Machine Method.\n",
    "As for now the script is not inside the machine, we create here the sentence\n",
    "and execute it later there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mv Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_globalvcs_2001_global_300m_72.tif Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global_finished']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"create the sentence to move all the rasters that are processed from one folder to another\"\"\"\n",
    "# VM 120 settings\n",
    "raster_path = r\"/home/ubuntu/vcs_wb/by_landcover/vegetation_carbon_stock_landcover_global/\"\n",
    "raster_destination = r\"/home/ubuntu/vcs_wb/by_landcover/already_processed_layers\"\n",
    "# VM 126 / 127 settings \n",
    "# raster_path = r\"Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global\"\n",
    "# raster_destination = r\"Z:/veg_c_storage_rawdata/vegetation_carbon_stock_landcover_global_finished\"\n",
    "\n",
    "sentence_list = []\n",
    "for file in files: # [0:1]\n",
    "    landcover_class = re.findall(r'\\d+', file)[1]\n",
    "    year = re.findall(r'\\d+', file)[0]\n",
    "    results_df = pd.read_csv(file)\n",
    "    if file.startswith(\"vegetation\"):\n",
    "        #create the sentence\n",
    "        sentence = \"mv \" + raster_path + \"/vcs_\" + year + \"_global_300m_\" + landcover_class + \".tif \" + raster_destination\n",
    "        sentence_list.append(sentence)\n",
    "        \n",
    "# mv /home/ubuntu/vcs_wb/by_landcover/vegetation_carbon_stock_landcover_global/vcs_2001_global_300m_72.tif /home/ubuntu/vcs_wb/by_landcover/already_processed_layers\n",
    "print(sentence_list[0:1])\n",
    "\n",
    "\"\"\"Export the sentence list into a table, copy and paste the result into the folder\"\"\"\n",
    "output_df = pd.Series(sentence_list)\n",
    "output_df.to_csv('sentence_list.csv') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
